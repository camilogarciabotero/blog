[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Miscellaneous",
    "section": "",
    "text": "Artists in the USA\n\n\n2 min\n\n\n\ntidytuesday\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n2021-09-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow do students’ loans change over time?\n\n\n1 min\n\n\n\ntidytuesday\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n2021-02-09\n\n\n\n\n\n\n\n\n\n\n\n\nK-mer counts on genomes\n\n\n3 min\n\n\n\nbioinformatics\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n2021-02-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNetflix titles per country\n\n\n4 min\n\n\n\ncode\n\n\nanalysis\n\n\ntidytuesday\n\n\n\n\n\n\n\n2021-04-30\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlastic pollution in countries\n\n\n1 min\n\n\n\ntidytuesday\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n2020-10-26\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPopulation benefited from waste water plants\n\n\n3 min\n\n\n\ntidytuesday\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n2021-09-20\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat’s the best coffee?\n\n\n2 min\n\n\n\ntidytuesday\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n2020-07-20\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2021-01-25-Kmer-analysis/kmer_counts.html",
    "href": "posts/2021-01-25-Kmer-analysis/kmer_counts.html",
    "title": "K-mer counts on genomes",
    "section": "",
    "text": "library(fs)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(reticulate)\nlibrary(ggprism)\nlibrary(ggrepel)\nlibrary(data.table)\nlibrary(knitr)"
  },
  {
    "objectID": "posts/2021-01-25-Kmer-analysis/kmer_counts.html#script-help-parallel-execution",
    "href": "posts/2021-01-25-Kmer-analysis/kmer_counts.html#script-help-parallel-execution",
    "title": "K-mer counts on genomes",
    "section": "Script help & parallel execution",
    "text": "Script help & parallel execution\n\npython ~/Projects/Biolibrary/kmer_count.py -h\n\nusage: kmer_count.py [-h] [-k K] input output\n\nCount the frecuency of a k-mer set given its size (k) along a genome or a set\nof genomes\n\npositional arguments:\n  input       Path to input fasta file\n  output      Path to put file/folder output\n\noptional arguments:\n  -h, --help  show this help message and exit\n  -k K        size of k-mer (default: 1)\n\n\n\nl ~/Projects/Random/Genomes/Pseudomonas_syringae_NZ* | parallel \"python kmer_count.py -k 2 {} {/.}.csv\"\n\n\n\nPseudomonas_syringae_NZ_CP005969.1_9mers.csv\nPseudomonas_syringae_NZ_CP005970.1_9mers.csv\nPseudomonas_syringae_NZ_CP006256.1_9mers.csv\nPseudomonas_syringae_NZ_CP007014.1_9mers.csv\nPseudomonas_syringae_NZ_CP011972.2_9mers.csv\nPseudomonas_syringae_NZ_CP012179.1_9mers.csv\nPseudomonas_syringae_NZ_CP013183.1_9mers.csv\nPseudomonas_syringae_NZ_CP017007.1_9mers.csv\nPseudomonas_syringae_NZ_CP017009.1_9mers.csv\nPseudomonas_syringae_NZ_CP018202.1_9mers.csv\nPseudomonas_syringae_NZ_CP019730.1_9mers.csv\nPseudomonas_syringae_NZ_CP019732.1_9mers.csv\nPseudomonas_syringae_NZ_CP019871.1_9mers.csv\nPseudomonas_syringae_NZ_CP024646.1_9mers.csv\nPseudomonas_syringae_NZ_CP024712.1_9mers.csv\nPseudomonas_syringae_NZ_CP026568.1_9mers.csv\nPseudomonas_syringae_NZ_CP028490.1_9mers.csv\nPseudomonas_syringae_NZ_CP032459.1_9mers.csv\nPseudomonas_syringae_NZ_CP032631.1_9mers.csv\nPseudomonas_syringae_NZ_CP032871.1_9mers.csv\nPseudomonas_syringae_NZ_CP034078.1_9mers.csv\nPseudomonas_syringae_NZ_CP045799.1_9mers.csv\nPseudomonas_syringae_NZ_CP047073.1_9mers.csv\nPseudomonas_syringae_NZ_CP047260.1_9mers.csv\nPseudomonas_syringae_NZ_CP047267.1_9mers.csv\nPseudomonas_syringae_NZ_CP067024.1_9mers.csv\nPseudomonas_syringae_NZ_CP068034.1_9mers.csv\nPseudomonas_syringae_NZ_LT962480.1_9mers.csv\nPseudomonas_syringae_NZ_LT962481.1_9mers.csv\nPseudomonas_syringae_NZ_LT963391.1_9mers.csv\nPseudomonas_syringae_NZ_LT963402.1_9mers.csv\nPseudomonas_syringae_NZ_LT963408.1_9mers.csv\nPseudomonas_syringae_NZ_LT963409.1_9mers.csv\nPseudomonas_syringae_NZ_LT985192.1_9mers.csv"
  },
  {
    "objectID": "posts/2021-02-09-Wealth-TT/wealth_debt.html",
    "href": "posts/2021-02-09-Wealth-TT/wealth_debt.html",
    "title": "How do students’ loans change over time?",
    "section": "",
    "text": "Using the tidytuesdayR package this task is easy:\n\ndata &lt;-  tidytuesdayR::tt_load(2021, week = 7)\nstudent_debt &lt;- data$student_debt\n\n\nhead(student_debt) |&gt; knitr::kable()\n\n\n\nyear\nrace\nloan_debt\nloan_debt_pct\n\n\n\n2016\nWhite\n11108.410\n0.3367511\n\n\n2016\nBlack\n14224.770\n0.4183588\n\n\n2016\nHispanic\n7493.999\n0.2189689\n\n\n2013\nWhite\n8363.605\n0.2845555\n\n\n2013\nBlack\n10302.660\n0.4122773\n\n\n2013\nHispanic\n3177.410\n0.1570289\n\n\n\n\n\nStudents debts over time\n\nlibrary(ggplot2)\nlibrary(ggprism)\n\nstudent_debt |&gt;\n  ggplot(aes(year, loan_debt, color = race)) +\n  geom_line() +\n  theme_minimal() +\n  theme(\n    legend.title = element_blank(),\n    axis.line = element_line(color = \"#000000\"),\n    axis.ticks = element_line(color = \"#000000\"),\n    panel.grid = element_line(color = \"#DDDDDD\", linetype = \"dotted\"), # Soft gray\n    legend.position = \"top\"\n  ) +\n  labs(\n    x = \"\",\n    y = \"Loan debt (USD)\"\n  ) +\n  scale_x_continuous(guide = \"prism_offset_minor\", limits = c(1990,2015)) +\n  scale_y_continuous(guide = \"prism_offset_minor\", limits = c(1000, 10000)) \n\nWarning: Removed 9 row(s) containing missing values (geom_path).\n\n\n\n\n\n\n\nCitationBibTeX citation:@misc{garcía-botero2021,\n  author = {García-Botero, Camilo},\n  title = {How Do Students’ Loans Change over Time?},\n  date = {2021-02-09},\n  url = {https://camilogarciabotero.github.io/blog},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nGarcía-Botero, Camilo. 2021. “How Do Students’ Loans Change over\nTime?” https://camilogarciabotero.github.io/blog."
  },
  {
    "objectID": "posts/2022-09-20-Wastes-TT/wastes.html",
    "href": "posts/2022-09-20-Wastes-TT/wastes.html",
    "title": "Population benefited from waste water plants",
    "section": "",
    "text": "As usual we can read the {tidytuesday} data directly from the source using the associated link:\n\nraw_data &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-09-20/HydroWASTE_v10.csv')\n\nRows: 58502 Columns: 25\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (5): WWTP_NAME, COUNTRY, CNTRY_ISO, STATUS, LEVEL\ndbl (20): WASTE_ID, SOURCE, ORG_ID, LAT_WWTP, LON_WWTP, QUAL_LOC, LAT_OUT, L...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.4 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.0      ✔ stringr 1.4.1 \n✔ readr   2.1.2      ✔ forcats 0.5.1 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()"
  },
  {
    "objectID": "posts/2022-09-20-Wastes-TT/wastes.html#some-conclusions",
    "href": "posts/2022-09-20-Wastes-TT/wastes.html#some-conclusions",
    "title": "Population benefited from waste water plants",
    "section": "Some conclusions",
    "text": "Some conclusions\nFrom the comparison between Colombia vs Venezuela benefited population from waste water plants Fig. 1, there are at least two important highlights. First, both countries display relatively low numbers plants given their extensions (this is something more of an intuition coming from the other comparisons as well), and a second thing is that there is actually no differences regarding the population they are attending. The opposite happens when comparing Germany vs. Netherlands benefited populations Fig. 2."
  },
  {
    "objectID": "posts/2020-10-26-Plastics-TT/plastics.html",
    "href": "posts/2020-10-26-Plastics-TT/plastics.html",
    "title": "Plastic pollution in countries",
    "section": "",
    "text": "Libraries\n\nlibrary(tidyverse) \nlibrary(tidytuesdayR)\nlibrary(ggprism)\nlibrary(rmarkdown)\nlibrary(countrycode)\n\nData import\nUsing the tidytuesdayR package this task is easy:\n\ndata &lt;-  tidytuesdayR::tt_load(2021, week = 5)\n\n--- Compiling #TidyTuesday Information for 2021-01-26 ----\n\n\n--- There is 1 file available ---\n\n\n--- Starting Download ---\n\n\n\n    Downloading file 1 of 1: `plastics.csv`\n\n\n--- Download complete ---\n\nplastics &lt;- data$plastics\n\nTotal plastic counts per country\n\nplastics_country &lt;- plastics |&gt;\n  mutate(country = case_when(\n    country == \"ECUADOR\" ~ \"Ecuador\",\n    country == \"NIGERIA\" ~ \"Nigeria\",\n    country == \"United Kingdom of Great Britain & Northern Ireland\" ~ \"Ireland\",\n    TRUE ~ country\n  )) |&gt;\n  group_by(country) |&gt; \n  summarise(\n    total = sum(grand_total)\n  ) |&gt;\n  arrange(desc(total)) |&gt;\n  mutate(abbreviation = countrycode(country, \"country.name\", \"cldr.name.en\")) |&gt;\n  mutate(flags = countrycode(country, \"country.name\", \"unicode.symbol\")) |&gt;\n  filter(!country == \"EMPTY\") |&gt;\n  mutate(total = ifelse(is.na(total), 0, total))\n\n\nplastics_country |&gt;\n  ggplot(aes(total, reorder(abbreviation, -total))) +\n  geom_col() +\n  geom_text(aes(label = total), size = 3, color = \"black\", hjust = -0.7) +\n  labs(\n    x = \"Total plastic counts [n]\",\n    y = \"\"\n  ) +\n  theme_minimal() +\n  scale_x_continuous(guide = \"prism_offset_minor\", limits = c(0, 270000)) +\n  coord_cartesian(expand = FALSE)\n\n\n\n\n\n\nCitationBibTeX citation:@online{garcía-botero2020,\n  author = {García-Botero, Camilo},\n  title = {Plastic Pollution in Countries},\n  date = {2020-10-26},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nGarcía-Botero, Camilo. 2020. “Plastic Pollution in\nCountries.” October 26, 2020."
  },
  {
    "objectID": "posts/2020-09-01-Netflix-TT/netflix.html",
    "href": "posts/2020-09-01-Netflix-TT/netflix.html",
    "title": "Netflix titles per country",
    "section": "",
    "text": "Since Netflix has been dominating all the straemaing platforms, several months ago decided to analyze the releasing titles nationality. This was possible by using several rstats libraries and the released dataset on the TidyTuesday project.\n\nlibrary(tidyverse)\nlibrary(tidytuesdayR)\nlibrary(ggprism)\nlibrary(gganimate)\nlibrary(gifski)\nlibrary(lubridate)\ntheme_set(theme_minimal())\n\nData import\n\nnetflix_titles &lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv') |&gt;\n  mutate(date_added = mdy(date_added)) |&gt;\n  mutate(year_added = year(date_added))\n\nReleased titles in 2020\n\n(\nmovies_country_year &lt;- netflix_titles |&gt; \n  select(country, release_year, type) |&gt; \n  filter(release_year == 2020, !is.na(country)) |&gt; \n  separate_rows(country, sep = \", \") |&gt; \n  count(country = fct_lump(country, 10), sort = TRUE, type) |&gt; \n  filter(country != \"Other\")\n)\n\n\n  \n\n\n\n\nggplot(movies_country_year, aes(n, reorder(country, n), label = n, fill = type)) +\n  geom_col(alpha = 0.7, width = 0.7, position = \"dodge2\") +\n  geom_text(size = 3, color = \"white\",  position = position_dodge(width = 0.8), hjust = -1) +\n  labs(\n    y = \"\",\n    x = \"\",\n    title = \"Released titles in 2020 available in Netflix\",\n    subtitle = \"Frequency of movies releases during 2020 (the pandemic) per country, that are available in Netflix \\n(Date do not correspond to Netflix release, but to the movies theirselves)\",\n    caption = \"Data: Kaggle \\n#TidyTuesday: 2021-04-17 \\nPlot: @Gaspardelanoche\"\n  ) +\n  theme(\n    plot.background = element_rect(fill = \"#111111\"),\n    panel.grid = element_line(color = \"#333333\", linetype = \"dotted\", size = 0.2),\n    panel.background = element_rect(fill = \"#111111\"),\n    axis.text.x = element_text(color = \"white\"),\n    axis.title = element_text(color = \"white\"),\n    axis.text.y = element_text(color = \"white\"),\n    axis.line = element_line(color = \"#333333\"),\n    axis.ticks = element_line(color = \"gray30\"),\n    plot.title = element_text(color = \"red\", size = 20),\n    plot.subtitle = element_text(color = \"white\", size = 13),\n    plot.caption = element_text(color = \"white\", size = 11),\n    legend.text = element_text(color = \"white\"),\n    legend.background = element_rect(fill = \"#111111\"),\n    legend.position = \"bottom\",\n    legend.title = element_blank()\n  ) +\n  scale_fill_manual(values = c(\"#FAF5FF\",\"#FF0000\"))\n\n\n\n\nReleases titles animated\n\n(\nmovies_country_years &lt;- netflix_titles |&gt; \n  select(country, release_year, type) |&gt; \n  filter(!is.na(country), !is.na(release_year)) |&gt; \n  separate_rows(country, sep = \", \") |&gt; \n  count(country = fct_lump(country,10), sort = TRUE, release_year) |&gt; \n  pivot_wider(names_from = release_year, values_from = n) |&gt;\n  # mutate(vars(\"2018\":\"2011\"), ~ if_else(is.na(.), '0', .))\n  mutate(across(everything(), ~replace_na(., 0)))\n  # pivot_longer(!c(country,), names_to = \"release_year\",  values_to = \"n\") |&gt; \n  # filter(country != \"Other\") |&gt; \n  # group_by(country) |&gt; \n  # arrange(release_year) |&gt;\n  # summarize(release_year, cumsum = cumsum(n), n, .groups = \"drop\") |&gt;\n  # # ungroup() |&gt; \n  # group_by(release_year) |&gt; \n  # mutate(ordering = rank(cumsum, ties.method = \"first\"), release_year = as.integer(release_year), cumsum_lab = as.character(cumsum))\n)\n\n\nmovies_country_years_animated &lt;- ggplot(movies_country_years, aes(ordering, group = country)) +\n  geom_tile(aes(y = cumsum/2, height = cumsum, width = 0.9), alpha = 0.5, fill = \"red\") +\n  geom_text(aes(y = 0, label = country), hjust = 1.1, color = \"white\") +\n  geom_text(aes(y = cumsum, label = cumsum_lab), size = 3, color = \"white\", hjust = -0.5) +\n  coord_flip(clip = \"off\", expand = FALSE) +  \n  labs(\n    y = \"\",\n    x = \"\",\n    title = \"Released titles in {frame_time} available in Netflix\",\n    subtitle = \"Frequency of movies released in {frame_time} country, that are available in Netflix \\n(Date do not correspond to Netflix release, but to the movies theirselves)\",\n    caption = \"Data: Kaggle \\n#TidyTuesday: 2021-04-17 \\nPlot: @Gaspardelanoche\"\n  ) +\n  theme(\n    plot.background = element_rect(fill = \"#111111\"),\n    panel.grid = element_line(color = \"#333333\", linetype = \"dotted\", size = 0.2),\n    panel.background = element_rect(fill = \"#111111\"),\n    axis.text.x = element_text(color = \"white\"),\n    axis.title = element_text(color = \"white\"),\n    axis.text.y = element_blank(),\n    axis.line = element_line(color = \"#333333\"),\n    axis.ticks = element_line(color = \"gray30\"),\n    plot.title = element_text(color = \"red\", size = 20),\n    plot.subtitle = element_text(color = \"white\", size = 13),\n    plot.caption = element_text(color = \"white\", size = 11),\n    legend.text = element_text(color = \"white\"),\n    legend.title = element_blank(),\n    plot.margin = margin(4, 4, 4, 4, \"cm\")\n  )  +\n  transition_time(release_year) +\n  ease_aes('bounce-in-out')\n\ngganimate::animate(movies_country_years_animated, nframes = 500, fps = 10, width = 800, height = 800, end_pause = 25)\n\n\n\nCitationBibTeX citation:@online{garcía-botero2021,\n  author = {García-Botero, Camilo},\n  title = {Netflix Titles Per Country},\n  date = {2021-04-30},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nGarcía-Botero, Camilo. 2021. “Netflix Titles Per Country.”\nApril 30, 2021."
  },
  {
    "objectID": "posts/2022-09-27-Artists-TT/artists.html",
    "href": "posts/2022-09-27-Artists-TT/artists.html",
    "title": "Artists in the USA",
    "section": "",
    "text": "This post covers the code and figures from the datascience workshop with R, where we explore some basics from dplyr and ggplot2 packages using the tidytuesday data set from the current week (2021-09-27)."
  },
  {
    "objectID": "posts/2022-09-27-Artists-TT/artists.html#data-manipulation",
    "href": "posts/2022-09-27-Artists-TT/artists.html#data-manipulation",
    "title": "Artists in the USA",
    "section": "Data manipulation",
    "text": "Data manipulation\n\nall_artists &lt;- artists |&gt;\n  mutate(across(state:type, as_factor)) |&gt;\n  drop_na(artists_n) |&gt;\n  group_by(race) |&gt;\n  summarize(n = sum(artists_n))\n\n\nall_artists"
  },
  {
    "objectID": "posts/2022-09-27-Artists-TT/artists.html#data-visualization",
    "href": "posts/2022-09-27-Artists-TT/artists.html#data-visualization",
    "title": "Artists in the USA",
    "section": "Data visualization",
    "text": "Data visualization\n\nggplot(all_artists) +\n  aes(y = reorder(race, n), x = n, fill = race, label = n) +\n  geom_col() +\n  geom_text() +\n  theme_bw() +\n  theme(\n    legend.position = \"none\",\n    axis.title.y = element_blank()\n  ) +\n  labs(\n    title = \"Number of artists across USA according to race\"\n  )"
  },
  {
    "objectID": "posts/2022-09-27-Artists-TT/artists.html#alluvial-plots",
    "href": "posts/2022-09-27-Artists-TT/artists.html#alluvial-plots",
    "title": "Artists in the USA",
    "section": "Alluvial plots",
    "text": "Alluvial plots\n\nfactored_artists &lt;- artists |&gt;\n  mutate(across(state:type, as_factor)) |&gt; \n  group_by(race, type, state) |&gt; \n  summarise(artists_n) |&gt;\n  drop_na()\n\n`summarise()` has grouped output by 'race', 'type'. You can override using the\n`.groups` argument.\n\n\n\nlibrary(ggalluvial)\nlibrary(ggfittext)\n\nggplot(factored_artists) +\n  aes(y = artists_n, axis1 = race, axis2 = type, fill = race) +\n  geom_stratum(alpha = .5) +\n  geom_alluvium() +\n  geom_fit_text(stat = \"stratum\", aes(label = after_stat(stratum))) +\n  theme_bw() +\n  theme(\n    legend.position = \"none\"\n  ) +\n  scale_fill_viridis_d() +\n  labs(\n    y = \"\"\n  )"
  },
  {
    "objectID": "posts/2020-08-31-Coffee-TT/coffee.html",
    "href": "posts/2020-08-31-Coffee-TT/coffee.html",
    "title": "What’s the best coffee?",
    "section": "",
    "text": "Introduction\nThis is my first Tidy Tuesday contribution and will be playing around a little bit with the coffee rating data.\nAs a coffee lover I felt that exploring a dataset about coffee was mandatory. The first question that came to me mind was: what is the best coffee and eventually, as looking a little bit deeper into dataset, which country has the best coffees.\nI decided then to compare coffee ratings across countries and the associated density of cups rated. Among the main findings it shows that one Ethiopian coffee came to be the best ranked and also that this country’s coffees are the best ranked while Haitian coffees show one of the widest range of ratings. Colombian coffee display a moderately good ratings and a very narrow range.\n\nlibrary(readr)\nlibrary(knitr)\nlibrary(tidyverse)\nlibrary(ggrepel)\nlibrary(ggridges)\nlibrary(hrbrthemes)\n\nCoffee rating distributions\n\ncoffee &lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-07/coffee_ratings.csv')\n\nhead(coffee) |&gt;\n kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntotal_cup_points\nspecies\nowner\ncountry_of_origin\nfarm_name\nlot_number\nmill\nico_number\ncompany\naltitude\nregion\nproducer\nnumber_of_bags\nbag_weight\nin_country_partner\nharvest_year\ngrading_date\nowner_1\nvariety\nprocessing_method\naroma\nflavor\naftertaste\nacidity\nbody\nbalance\nuniformity\nclean_cup\nsweetness\ncupper_points\nmoisture\ncategory_one_defects\nquakers\ncolor\ncategory_two_defects\nexpiration\ncertification_body\ncertification_address\ncertification_contact\nunit_of_measurement\naltitude_low_meters\naltitude_high_meters\naltitude_mean_meters\n\n\n\n90.58\nArabica\nmetad plc\nEthiopia\nmetad plc\nNA\nmetad plc\n2014/2015\nmetad agricultural developmet plc\n1950-2200\nguji-hambela\nMETAD PLC\n300\n60 kg\nMETAD Agricultural Development plc\n2014\nApril 4th, 2015\nmetad plc\nNA\nWashed / Wet\n8.67\n8.83\n8.67\n8.75\n8.50\n8.42\n10\n10\n10\n8.75\n0.12\n0\n0\nGreen\n0\nApril 3rd, 2016\nMETAD Agricultural Development plc\n309fcf77415a3661ae83e027f7e5f05dad786e44\n19fef5a731de2db57d16da10287413f5f99bc2dd\nm\n1950\n2200\n2075\n\n\n89.92\nArabica\nmetad plc\nEthiopia\nmetad plc\nNA\nmetad plc\n2014/2015\nmetad agricultural developmet plc\n1950-2200\nguji-hambela\nMETAD PLC\n300\n60 kg\nMETAD Agricultural Development plc\n2014\nApril 4th, 2015\nmetad plc\nOther\nWashed / Wet\n8.75\n8.67\n8.50\n8.58\n8.42\n8.42\n10\n10\n10\n8.58\n0.12\n0\n0\nGreen\n1\nApril 3rd, 2016\nMETAD Agricultural Development plc\n309fcf77415a3661ae83e027f7e5f05dad786e44\n19fef5a731de2db57d16da10287413f5f99bc2dd\nm\n1950\n2200\n2075\n\n\n89.75\nArabica\ngrounds for health admin\nGuatemala\nsan marcos barrancas “san cristobal cuch\nNA\nNA\nNA\nNA\n1600 - 1800 m\nNA\nNA\n5\n1\nSpecialty Coffee Association\nNA\nMay 31st, 2010\nGrounds for Health Admin\nBourbon\nNA\n8.42\n8.50\n8.42\n8.42\n8.33\n8.42\n10\n10\n10\n9.25\n0.00\n0\n0\nNA\n0\nMay 31st, 2011\nSpecialty Coffee Association\n36d0d00a3724338ba7937c52a378d085f2172daa\n0878a7d4b9d35ddbf0fe2ce69a2062cceb45a660\nm\n1600\n1800\n1700\n\n\n89.00\nArabica\nyidnekachew dabessa\nEthiopia\nyidnekachew dabessa coffee plantation\nNA\nwolensu\nNA\nyidnekachew debessa coffee plantation\n1800-2200\noromia\nYidnekachew Dabessa Coffee Plantation\n320\n60 kg\nMETAD Agricultural Development plc\n2014\nMarch 26th, 2015\nYidnekachew Dabessa\nNA\nNatural / Dry\n8.17\n8.58\n8.42\n8.42\n8.50\n8.25\n10\n10\n10\n8.67\n0.11\n0\n0\nGreen\n2\nMarch 25th, 2016\nMETAD Agricultural Development plc\n309fcf77415a3661ae83e027f7e5f05dad786e44\n19fef5a731de2db57d16da10287413f5f99bc2dd\nm\n1800\n2200\n2000\n\n\n88.83\nArabica\nmetad plc\nEthiopia\nmetad plc\nNA\nmetad plc\n2014/2015\nmetad agricultural developmet plc\n1950-2200\nguji-hambela\nMETAD PLC\n300\n60 kg\nMETAD Agricultural Development plc\n2014\nApril 4th, 2015\nmetad plc\nOther\nWashed / Wet\n8.25\n8.50\n8.25\n8.50\n8.42\n8.33\n10\n10\n10\n8.58\n0.12\n0\n0\nGreen\n2\nApril 3rd, 2016\nMETAD Agricultural Development plc\n309fcf77415a3661ae83e027f7e5f05dad786e44\n19fef5a731de2db57d16da10287413f5f99bc2dd\nm\n1950\n2200\n2075\n\n\n88.83\nArabica\nji-ae ahn\nBrazil\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n100\n30 kg\nSpecialty Coffee Institute of Asia\n2013\nSeptember 3rd, 2013\nJi-Ae Ahn\nNA\nNatural / Dry\n8.58\n8.42\n8.42\n8.50\n8.25\n8.33\n10\n10\n10\n8.33\n0.11\n0\n0\nBluish-Green\n1\nSeptember 3rd, 2014\nSpecialty Coffee Institute of Asia\n726e4891cf2c9a4848768bd34b668124d12c4224\nb70da261fcc84831e3e9620c30a8701540abc200\nm\nNA\nNA\nNA\n\n\n\n\n\n\ncoffee |&gt;\n  drop_na(any_of(\"country_of_origin\")) |&gt;\n  filter(aroma != 0 & !country_of_origin %in% c(\"Zambia\", \"Rwanda\", \"Papua New Guinea\", \"Japan\", \"Mauritius\", \"Cote d?Ivoire\", \"Burundi\")) |&gt;\n  mutate(country_of_origin = fct_reorder(country_of_origin, total_cup_points)) |&gt; \n  ggplot(aes(x = total_cup_points, y = country_of_origin, fill = stat(x), label = owner)) +\n  geom_density_ridges_gradient(show.legend = T, alpha = .5, point_alpha = 0.5, jittered_points = TRUE) +\n  theme_ipsum() +\n  scale_fill_viridis_c(alpha = 0.7) +\n  ylab(\"\") +\n  xlab(\"Total cup points\") +\n  labs(\n    title = \"Comparison of coffee's ratings across countries and its distribution\",\n    subtitle = \"Ethiopian coffees seem to be the best. Latinoamerican countries were more abundant in the competition\",\n    caption = \"Data: TidyTuesday week 28. Plot: @Gaspardelanoche\",\n    fill = \"Total cup points\"\n  ) +\n  theme(\n    plot.title = element_text(size = 20, face = \"bold\"),\n    plot.subtitle = element_text(size = 18),\n    axis.title.x = element_text(size = 18),\n    axis.title.y = element_text(size = 18),\n    axis.text.y = element_text(size = 18),\n    plot.caption = element_text(size = 16)\n  ) +\n  geom_label_repel(\n    data = subset(coffee, total_cup_points &gt; 89),\n    force = 10,\n    xlim = c(85, NA)\n  )\n\nPicking joint bandwidth of 0.919\n\n\n\n\n\n\n\nCitationBibTeX citation:@misc{garcía-botero2020,\n  author = {García-Botero, Camilo},\n  title = {What’s the Best Coffee?},\n  date = {2020-07-20},\n  url = {https://camilogarciabotero.github.io/blog},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nGarcía-Botero, Camilo. 2020. “What’s the Best Coffee?” https://camilogarciabotero.github.io/blog."
  }
]